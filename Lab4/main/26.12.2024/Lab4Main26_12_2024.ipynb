{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rODb9vHvIEbp"
   },
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napomena otvori drug Anaconda Prompt i site paketi sto ti trebaat instalirajgi so conda install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Vaka otvoram Anaconda Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda install pytorch torchvision pytorch-cuda=11.8 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Napravi check direkno od Anaconda Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -c \"import torch; print(torch.__version__); print(torch.version.cuda); print(torch.cuda.get_device_properties(0)); print(torch.randn(1).cuda()); print(torch.cuda.is_available())\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Pa od Anaconda Prompt otvorisi kaj tie notebook filot primer na Disk F mie vo folder VNP/Lab4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(base) C:\\Users\\Beqir> F:\n",
    "\n",
    "(base) F:\\>cd VNP/Lab4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Sega pisi samo \"jupyter notebook\" i ke ti se otvori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Napravi check vo notbook so torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U4KmHBd2cdx9"
   },
   "outputs": [],
   "source": [
    "# Add as many imports as you need.\n",
    "import torch\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "11.8\n",
      "_CudaDeviceProperties(name='NVIDIA GeForce GTX 1050', major=6, minor=1, total_memory=4095MB, multi_processor_count=5, uuid=c87c7efa-5d3d-89c4-c2b7-218d5d7cd65e, L2_cache_size=0MB)\n",
      "tensor([-0.4529], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.get_device_properties(0))\n",
    "print(torch.randn(1).cuda())\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNMMoUiUIW3L"
   },
   "source": [
    "# Laboratory Exercise - Run Mode (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rAh_91OIjeS"
   },
   "source": [
    "## Introduction\n",
    "This laboratory assignment's primary objective is to fine-tune a pre-trained language model for binary classification on a dataset consisting of Spotify user reviews. The dataset contains two attributes:\n",
    "\n",
    "+ **review** - A text column containing user feedback, opinions, and experiences with the Spotify application.\n",
    "+ **sentiment** - A categorical column indicating whether the review has a positive or negative sentiment.\n",
    "\n",
    "Your task involves training a model to predict the **sentiment** (either \"positive\" or \"negative\") based on the content of the **review**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zBYI-EypaWom"
   },
   "source": [
    "## The Spotify User Reviews Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCm1qm1mZwMr"
   },
   "source": [
    "Load the dataset using the `datasets` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KMOn4fgcZn8s"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "dataset = load_dataset('csv', data_files='spotify-user-reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['review', 'label']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tls69_PrbJKW"
   },
   "source": [
    "## Dataset Splitting\n",
    "Partition the dataset into training and testing sets with an 80:20 ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PjGGGMxebeoB"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "test_dataset = Dataset.from_dict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLnr8v_dWO1i"
   },
   "source": [
    "## Tokenization\n",
    "Tokenize the texts using the `AutoTokenizer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    # Check if 'review' column exists\n",
    "    return tokenizer(\n",
    "        batch['review'],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "esakOh8iWYEN"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a76b246de254199aae5250ca912d4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7bb2eca9474f7da5456bb726ecb520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "\n",
    "# Apply tokenization\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Ensure the format is set for PyTorch\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d037acacbe4dc3a0374441b58d3233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eea25680ab040f5b02d39402868ae91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map the string labels to integers (e.g., 'positive' -> 1, 'negative' -> 0)\n",
    "label_mapping = {\"positive\": 1, \"negative\": 0}\n",
    "\n",
    "def map_labels(example):\n",
    "    example['label'] = label_mapping[example['label']]\n",
    "    return example\n",
    "\n",
    "# Apply the label mapping\n",
    "train_dataset = train_dataset.map(map_labels)\n",
    "test_dataset = test_dataset.map(map_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIkAR1Hibiwr"
   },
   "source": [
    "## Fine-tuning a Pre-trained Language Model for Classification\n",
    "Fine-tune a pre-trained language model for classification on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWn1pafKbnxH"
   },
   "source": [
    "Define the model using the `AutoModelForSequenceClassification` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IXFIrQthbnkb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load pre-trained model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use the first available GPU\n",
    "    model.to(device)               # Move the model to GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")   # Use CPU if GPU is not available\n",
    "    model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuQCSxZbYJOq"
   },
   "source": [
    "Define the traning parameters using the `TrainingArguments` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p3sVs-L1YJHu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    no_cuda=False,  # Ensure CUDA is used\n",
    "    logging_dir='./logs',\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVvRS4L1YKHp"
   },
   "source": [
    "Define the training using the `Trainer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "O7cyG3PhYJ_M"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 05:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.207325</td>\n",
       "      <td>0.919000</td>\n",
       "      <td>0.919081</td>\n",
       "      <td>0.918164</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=0.2656896667480469, metrics={'train_runtime': 334.5697, 'train_samples_per_second': 23.911, 'train_steps_per_second': 0.747, 'total_flos': 264934797312000.0, 'train_loss': 0.2656896667480469, 'epoch': 1.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "from transformers import Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Define metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFZr21HxYkko"
   },
   "source": [
    "Fine-tune (train) the pre-trained lanugage model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9Dz0P11Ykeh"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyXZwAVab8Cp"
   },
   "source": [
    "Use the trained model to make predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "EvMfVum6b_9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VxAvDPtcNCh"
   },
   "source": [
    "Assess the performance of the model by using different metrics provided by the `scikit-learn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "V4axpktycQhp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.20732472836971283, 'test_accuracy': 0.919, 'test_f1': 0.919080919080919, 'test_precision': 0.9181636726546906, 'test_recall': 0.92, 'test_runtime': 23.5212, 'test_samples_per_second': 85.03, 'test_steps_per_second': 10.629}\n"
     ]
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "print(predictions.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwnD_qSpIeXG"
   },
   "source": [
    "# Laboratory Exercise - Bonus Task (+ 2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "At5xnEDq3A2h"
   },
   "source": [
    "Implement a machine learning pipeline to classify Spotify user reviews as positive or negative. Use TF-IDF vectorization to transform the review text into numerical features, and train a logistic regression model on the transformed data. Split the dataset into training and testing sets, fit the pipeline on the training data, and evaluate its performance using metrics such as precision, recall, and F1-score. To gain insights into the most influential words or phrases associated with positive and negative reviews, analyze the coefficients from the logistic regression model trained on the TF-IDF features. Present the top keywords for each sentiment in a table or a bar chart to provide a clear understanding of the terms driving user feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "akxvW5SZ3DoV"
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Vectorize\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(train_data['review'])\n",
    "X_test = vectorizer.transform(test_data['review'])\n",
    "\n",
    "# Labels\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88      1000\n",
      "    positive       0.90      0.85      0.87      1000\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.88      0.88      0.88      2000\n",
      "weighted avg       0.88      0.88      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Positive  Negative\n",
      "0      music       fix\n",
      "1      enjoy       not\n",
      "2  excellent  annoying\n",
      "3    awesome    update\n",
      "4       nice     worst\n",
      "5    amazing     doesn\n",
      "6      great       ads\n",
      "7       best       why\n",
      "8       good       but\n",
      "9       love      only\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = clf.coef_.flatten()\n",
    "top_positive_indices = np.argsort(coefficients)[-10:]  # Top 10 positive\n",
    "top_negative_indices = np.argsort(coefficients)[:10]   # Top 10 negative\n",
    "\n",
    "# Get feature names\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "top_features = pd.DataFrame({\n",
    "    \"Positive\": [features[i] for i in top_positive_indices],\n",
    "    \"Negative\": [features[i] for i in top_negative_indices]\n",
    "})\n",
    "print(top_features)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
